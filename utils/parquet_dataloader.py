"""
Parquetæ•°æ®é›†åŠ è½½å™¨ - ç”¨äºé˜¶æ®µ1åˆ†è§£ç½‘ç»œé¢„è®­ç»ƒ

ä¸ICEdit_contrastiveçš„æ•°æ®æ ¼å¼å®Œå…¨å…¼å®¹ï¼š
- åŠ è½½parquetæ–‡ä»¶
- æå– src_img (å¯è§å…‰), edited_img (çº¢å¤–), panoptic_img (è¯­ä¹‰)
- ä½¿ç”¨fixed_split.pyç”Ÿæˆçš„åˆ’åˆ†
"""

import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
from pathlib import Path
import os

# å¯¼å…¥fixed_splitå·¥å…·
from .fixed_split import load_split_dataset


class DecompositionDataset(Dataset):
    """
    ç”¨äºåˆ†è§£ç½‘ç»œé¢„è®­ç»ƒçš„æ•°æ®é›†

    ä»parquetåŠ è½½ä¸‰æ¨¡æ€æ•°æ®ï¼šå¯è§å…‰ã€çº¢å¤–ã€è¯­ä¹‰åˆ†å‰²
    """
    def __init__(
        self,
        dataset,  # ä»load_split_dataset()è¿”å›çš„HF datasetå¯¹è±¡
        image_size=512,
        normalize=True,
    ):
        """
        Args:
            dataset: HuggingFace Datasetå¯¹è±¡ï¼ˆå·²ç»è¿‡selectåˆ’åˆ†ï¼‰
            image_size: å›¾åƒresizeå°ºå¯¸
            normalize: æ˜¯å¦ä½¿ç”¨ImageNetå½’ä¸€åŒ–ï¼ˆç”¨äºResNet backboneï¼‰
        """
        self.dataset = dataset
        self.image_size = image_size

        # å›¾åƒå˜æ¢
        transform_list = [
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
        ]

        if normalize:
            # ImageNetå½’ä¸€åŒ–ï¼ˆResNeté¢„è®­ç»ƒä½¿ç”¨ï¼‰
            transform_list.append(
                transforms.Normalize(
                    mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]
                )
            )

        self.transform = transforms.Compose(transform_list)

        # è¯­ä¹‰å›¾ä¸éœ€è¦å½’ä¸€åŒ–ï¼Œä¿æŒåŸå§‹é¢œè‰²
        self.semantic_transform = transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        """
        è¿”å›:
            rgb: [3, H, W] å¯è§å…‰å›¾åƒï¼ˆImageNetå½’ä¸€åŒ–ï¼‰
            infrared: [3, H, W] çº¢å¤–å›¾åƒï¼ˆä»…ToTensorï¼Œä¸å½’ä¸€åŒ–ï¼ï¼‰
            semantic: [3, H, W] è¯­ä¹‰åˆ†å‰²å›¾ï¼ˆä»…ToTensorï¼Œä¿ç•™é¢œè‰²ä¿¡æ¯ï¼‰
        """
        sample = self.dataset[idx]

        # åŠ è½½å›¾åƒ
        rgb_img = sample['src_img']  # PIL Image
        ir_img = sample['edited_img']  # PIL Image
        semantic_img = sample['panoptic_img']  # PIL Image (é¢œè‰²åˆ†å—)

        # ç¡®ä¿æ˜¯RGBæ¨¡å¼
        if rgb_img.mode != 'RGB':
            rgb_img = rgb_img.convert('RGB')
        if ir_img.mode != 'RGB':
            ir_img = ir_img.convert('RGB')
        if semantic_img.mode != 'RGB':
            semantic_img = semantic_img.convert('RGB')

        # åº”ç”¨å˜æ¢
        rgb = self.transform(rgb_img)  # ImageNetå½’ä¸€åŒ–ï¼ˆResNetéœ€è¦ï¼‰

        # âš ï¸ çº¢å¤–å›¾ä¸å½’ä¸€åŒ–ï¼ä¿æŒ [0, 1] èŒƒå›´
        infrared = self.semantic_transform(ir_img)  # åªåš Resize + ToTensor

        semantic = self.semantic_transform(semantic_img)  # åªåš Resize + ToTensor

        return {
            'rgb': rgb,
            'infrared': infrared,
            'semantic': semantic,
        }


def create_dataloaders(
    parquet_path,
    split_file='./data/dataset_split.json',
    batch_size=8,
    num_workers=4,
    image_size=512,
    normalize=True,
):
    """
    åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨

    Args:
        parquet_path: parquetæ–‡ä»¶è·¯å¾„
        split_file: æ•°æ®é›†åˆ’åˆ†JSONæ–‡ä»¶è·¯å¾„
        batch_size: æ‰¹æ¬¡å¤§å°
        num_workers: DataLoaderå·¥ä½œè¿›ç¨‹æ•°
        image_size: å›¾åƒå°ºå¯¸
        normalize: æ˜¯å¦å½’ä¸€åŒ–

    Returns:
        train_loader, val_loader
    """
    # ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ç¼“å­˜è·¯å¾„ï¼ˆä¸ICEditä¸€è‡´ï¼‰
    cache_dir = os.environ.get('HF_DATASETS_CACHE', None)
    if cache_dir:
        print(f"ğŸ“¦ ä½¿ç”¨ç¼“å­˜è·¯å¾„: {cache_dir}")

    # åŠ è½½å·²åˆ’åˆ†çš„æ•°æ®é›†
    print(f"ğŸ“‚ åŠ è½½æ•°æ®é›†: {parquet_path}")
    train_dataset_hf, val_dataset_hf = load_split_dataset(
        parquet_path=parquet_path,
        split_file=split_file,
        create_if_not_exists=True
    )

    # åˆ›å»ºPyTorch Dataset
    print("ğŸ”§ åˆ›å»ºPyTorchæ•°æ®é›†...")
    train_dataset = DecompositionDataset(
        train_dataset_hf,
        image_size=image_size,
        normalize=normalize,
    )

    val_dataset = DecompositionDataset(
        val_dataset_hf,
        image_size=image_size,
        normalize=normalize,
    )

    # åˆ›å»ºDataLoader
    print("ğŸ”§ åˆ›å»ºDataLoader...")
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True,
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=False,
    )

    print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ:")
    print(f"   è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬, {len(train_loader)} æ‰¹æ¬¡")
    print(f"   éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬, {len(val_loader)} æ‰¹æ¬¡")

    return train_loader, val_loader


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='æµ‹è¯•æ•°æ®åŠ è½½å™¨')
    parser.add_argument('--parquet', type=str, required=True,
                       help='Parquetæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--split_file', type=str, default='./data/dataset_split.json',
                       help='æ•°æ®é›†åˆ’åˆ†æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch_size', type=int, default=4,
                       help='æ‰¹æ¬¡å¤§å°')

    args = parser.parse_args()

    print("=" * 70)
    print("æµ‹è¯•Parquetæ•°æ®åŠ è½½å™¨")
    print("=" * 70)

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader = create_dataloaders(
        parquet_path=args.parquet,
        split_file=args.split_file,
        batch_size=args.batch_size,
        num_workers=0,  # æµ‹è¯•æ—¶ä½¿ç”¨å•è¿›ç¨‹
        image_size=512,
    )

    # åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡æµ‹è¯•
    print("\n" + "=" * 70)
    print("åŠ è½½æµ‹è¯•æ‰¹æ¬¡...")
    print("=" * 70)

    batch = next(iter(train_loader))

    print(f"\nâœ… æ‰¹æ¬¡åŠ è½½æˆåŠŸ!")
    print(f"   RGBå½¢çŠ¶: {batch['rgb'].shape}")
    print(f"   çº¢å¤–å½¢çŠ¶: {batch['infrared'].shape}")
    print(f"   è¯­ä¹‰å½¢çŠ¶: {batch['semantic'].shape}")
    print(f"   RGBèŒƒå›´: [{batch['rgb'].min():.3f}, {batch['rgb'].max():.3f}]")
    print(f"   çº¢å¤–èŒƒå›´: [{batch['infrared'].min():.3f}, {batch['infrared'].max():.3f}]")
    print(f"   è¯­ä¹‰èŒƒå›´: [{batch['semantic'].min():.3f}, {batch['semantic'].max():.3f}]")

    print("\n" + "=" * 70)
    print("âœ… æ•°æ®åŠ è½½å™¨æµ‹è¯•é€šè¿‡!")
    print("=" * 70)
