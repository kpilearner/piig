"""
è¯Šæ–­è„šæœ¬ï¼šæ£€æŸ¥è®­ç»ƒæµç¨‹ä¸­çš„æ•°æ®å’Œæ¨¡å‹

ç”¨äºæ’æŸ¥lossä¸é™çš„é—®é¢˜
"""

import torch
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from utils.parquet_dataloader import create_dataloaders
from decomposition.model import MultiTaskDecompositionNet, PhysicsInspiredFusion
from decomposition.pseudo_labels import (
    generate_pseudo_intensity,
    generate_pseudo_material_from_panoptic,
    generate_pseudo_context
)
import matplotlib.pyplot as plt
import numpy as np

def check_data_loading():
    """æ£€æŸ¥æ•°æ®åŠ è½½"""
    print("=" * 70)
    print("1. æ£€æŸ¥æ•°æ®åŠ è½½")
    print("=" * 70)

    # åˆ›å»ºdataloader
    train_loader, _ = create_dataloaders(
        parquet_path="/root/autodl-tmp/qyt_contrasctivew/lmr_contrastive/dataset/pid_llvip_dataset_fixed.parquet",
        split_file="./data/dataset_split.json",
        batch_size=2,
        num_workers=0,
        image_size=512,
        normalize=True,
    )

    # åŠ è½½ä¸€ä¸ªbatch
    batch = next(iter(train_loader))

    print(f"\nâœ… æ•°æ®å½¢çŠ¶:")
    print(f"   RGB: {batch['rgb'].shape}")
    print(f"   Infrared: {batch['infrared'].shape}")
    print(f"   Semantic: {batch['semantic'].shape}")

    print(f"\nâœ… æ•°æ®èŒƒå›´:")
    print(f"   RGB: [{batch['rgb'].min():.3f}, {batch['rgb'].max():.3f}]")
    print(f"   Infrared: [{batch['infrared'].min():.3f}, {batch['infrared'].max():.3f}]")
    print(f"   Semantic: [{batch['semantic'].min():.3f}, {batch['semantic'].max():.3f}]")

    # æ£€æŸ¥æ˜¯å¦æœ‰NaN
    print(f"\nâœ… NaNæ£€æŸ¥:")
    print(f"   RGBæœ‰NaN: {torch.isnan(batch['rgb']).any()}")
    print(f"   Infraredæœ‰NaN: {torch.isnan(batch['infrared']).any()}")
    print(f"   Semanticæœ‰NaN: {torch.isnan(batch['semantic']).any()}")

    return batch


def check_pseudo_labels(batch):
    """æ£€æŸ¥ä¼ªæ ‡ç­¾ç”Ÿæˆ"""
    print("\n" + "=" * 70)
    print("2. æ£€æŸ¥ä¼ªæ ‡ç­¾ç”Ÿæˆ")
    print("=" * 70)

    rgb = batch['rgb']
    infrared = batch['infrared']
    semantic = batch['semantic']

    # ç”Ÿæˆä¼ªæ ‡ç­¾
    ir_gray = infrared.mean(dim=1, keepdim=True)

    print(f"\nâœ… çº¢å¤–ç°åº¦å›¾:")
    print(f"   å½¢çŠ¶: {ir_gray.shape}")
    print(f"   èŒƒå›´: [{ir_gray.min():.3f}, {ir_gray.max():.3f}]")

    # Intensity
    pseudo_intensity = generate_pseudo_intensity(ir_gray, normalize=True)
    print(f"\nâœ… Pseudo Intensity:")
    print(f"   å½¢çŠ¶: {pseudo_intensity.shape}")
    print(f"   èŒƒå›´: [{pseudo_intensity.min():.3f}, {pseudo_intensity.max():.3f}]")
    print(f"   å‡å€¼: {pseudo_intensity.mean():.3f}")
    print(f"   æ ‡å‡†å·®: {pseudo_intensity.std():.3f}")

    # Material
    pseudo_material = generate_pseudo_material_from_panoptic(semantic, num_classes=32)
    print(f"\nâœ… Pseudo Material:")
    print(f"   å½¢çŠ¶: {pseudo_material.shape}")
    print(f"   èŒƒå›´: [{pseudo_material.min()}, {pseudo_material.max()}]")
    print(f"   å”¯ä¸€ç±»åˆ«æ•°: {len(torch.unique(pseudo_material))}")

    # Context
    pseudo_context = generate_pseudo_context(rgb, ir_gray)
    print(f"\nâœ… Pseudo Context:")
    print(f"   å½¢çŠ¶: {pseudo_context.shape}")
    print(f"   èŒƒå›´: [{pseudo_context.min():.3f}, {pseudo_context.max():.3f}]")

    return {
        'pseudo_intensity': pseudo_intensity,
        'pseudo_material': pseudo_material,
        'pseudo_context': pseudo_context,
    }


def check_model_forward(batch, device='cuda'):
    """æ£€æŸ¥æ¨¡å‹å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 70)
    print("3. æ£€æŸ¥æ¨¡å‹å‰å‘ä¼ æ’­")
    print("=" * 70)

    # åˆ›å»ºæ¨¡å‹
    model = MultiTaskDecompositionNet(
        backbone='resnet50',
        pretrained=True,
        num_material_classes=32,
        context_channels=8,
    ).to(device)

    fusion = PhysicsInspiredFusion(
        num_material_classes=32,
        context_channels=8,
        hidden_dim=64,
    ).to(device)

    model.eval()
    fusion.eval()

    rgb = batch['rgb'].to(device)

    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        pred_intensity, pred_material, pred_context = model(rgb)
        fused_output = fusion(pred_intensity, pred_material, pred_context)

    print(f"\nâœ… æ¨¡å‹è¾“å‡º:")
    print(f"   Intensity: {pred_intensity.shape}, èŒƒå›´: [{pred_intensity.min():.3f}, {pred_intensity.max():.3f}]")
    print(f"   Material: {pred_material.shape}, èŒƒå›´: [{pred_material.min():.3f}, {pred_material.max():.3f}]")
    print(f"   Context: {pred_context.shape}, èŒƒå›´: [{pred_context.min():.3f}, {pred_context.max():.3f}]")
    print(f"   Fused: {fused_output.shape}, èŒƒå›´: [{fused_output.min():.3f}, {fused_output.max():.3f}]")

    # æ£€æŸ¥æ¢¯åº¦
    model.train()
    fusion.train()

    pred_intensity, pred_material, pred_context = model(rgb)
    fused_output = fusion(pred_intensity, pred_material, pred_context)

    # ç®€å•loss
    loss = fused_output.mean()
    loss.backward()

    # æ£€æŸ¥æ˜¯å¦æœ‰æ¢¯åº¦
    has_grad = False
    for name, param in model.named_parameters():
        if param.grad is not None and param.grad.abs().sum() > 0:
            has_grad = True
            print(f"\nâœ… æ¢¯åº¦æ£€æŸ¥ (ç¤ºä¾‹): {name}")
            print(f"   æ¢¯åº¦èŒƒæ•°: {param.grad.norm():.6f}")
            break

    if not has_grad:
        print("\nâŒ è­¦å‘Š: æ¨¡å‹æ²¡æœ‰æ¢¯åº¦ï¼")

    return {
        'pred_intensity': pred_intensity.detach().cpu(),
        'pred_material': pred_material.detach().cpu(),
        'pred_context': pred_context.detach().cpu(),
        'fused_output': fused_output.detach().cpu(),
    }


def check_loss_computation(batch, pseudo_labels, predictions):
    """æ£€æŸ¥æŸå¤±è®¡ç®—"""
    print("\n" + "=" * 70)
    print("4. æ£€æŸ¥æŸå¤±è®¡ç®—")
    print("=" * 70)

    from decomposition.losses import MultiTaskPretrainLoss

    criterion = MultiTaskPretrainLoss(
        lambda_intensity=1.0,
        lambda_material=1.0,
        lambda_context=0.5,
        lambda_fusion=2.0,
    )

    # å‡†å¤‡æ•°æ®
    ir_gray = batch['infrared'].mean(dim=1, keepdim=True)

    # è®¡ç®—æŸå¤±
    loss, losses = criterion(
        predictions['pred_intensity'],
        predictions['pred_material'],
        predictions['pred_context'],
        predictions['fused_output'],
        pseudo_labels['pseudo_intensity'],
        pseudo_labels['pseudo_material'],
        pseudo_labels['pseudo_context'],
        ir_gray
    )

    print(f"\nâœ… å„é¡¹æŸå¤±:")
    print(f"   Total: {losses['total']:.4f}")
    print(f"   Intensity: {losses['intensity']:.4f}")
    print(f"   Material: {losses['material']:.4f}")
    print(f"   Context: {losses['context']:.4f}")
    print(f"   Fusion: {losses['fusion']:.4f}")

    # åˆ†ææŸå¤±å¤§å°
    if losses['total'] > 100:
        print(f"\nâš ï¸  è­¦å‘Š: Total losså¾ˆå¤§ ({losses['total']:.2f})ï¼Œå¯èƒ½æœ‰æ•°å€¼é—®é¢˜")

    if losses['material'] > 10:
        print(f"\nâš ï¸  è­¦å‘Š: Material losså¾ˆå¤§ ({losses['material']:.2f})ï¼Œæ£€æŸ¥ç±»åˆ«æ•°é‡")

    return losses


def visualize_outputs(batch, pseudo_labels, predictions, save_path='debug_vis.png'):
    """å¯è§†åŒ–å¯¹æ¯”"""
    print("\n" + "=" * 70)
    print("5. å¯è§†åŒ–è¾“å‡º")
    print("=" * 70)

    fig, axes = plt.subplots(3, 4, figsize=(16, 12))

    # ç¬¬ä¸€è¡Œï¼šè¾“å…¥
    axes[0, 0].imshow(batch['rgb'][0].permute(1, 2, 0).numpy() * 0.5 + 0.5)
    axes[0, 0].set_title('Input RGB')
    axes[0, 0].axis('off')

    axes[0, 1].imshow(batch['infrared'][0].permute(1, 2, 0).numpy())
    axes[0, 1].set_title('Target Infrared')
    axes[0, 1].axis('off')

    axes[0, 2].imshow(batch['semantic'][0].permute(1, 2, 0).numpy())
    axes[0, 2].set_title('Semantic')
    axes[0, 2].axis('off')

    axes[0, 3].axis('off')

    # ç¬¬äºŒè¡Œï¼šä¼ªæ ‡ç­¾
    axes[1, 0].imshow(pseudo_labels['pseudo_intensity'][0, 0].numpy(), cmap='hot')
    axes[1, 0].set_title('Pseudo Intensity')
    axes[1, 0].axis('off')

    axes[1, 1].imshow(pseudo_labels['pseudo_material'][0].numpy(), cmap='tab20')
    axes[1, 1].set_title('Pseudo Material')
    axes[1, 1].axis('off')

    axes[1, 2].imshow(pseudo_labels['pseudo_context'][0, 0].numpy(), cmap='viridis')
    axes[1, 2].set_title('Pseudo Context (ch0)')
    axes[1, 2].axis('off')

    axes[1, 3].axis('off')

    # ç¬¬ä¸‰è¡Œï¼šé¢„æµ‹
    axes[2, 0].imshow(predictions['pred_intensity'][0, 0].numpy(), cmap='hot')
    axes[2, 0].set_title('Pred Intensity')
    axes[2, 0].axis('off')

    axes[2, 1].imshow(predictions['pred_material'][0].argmax(0).numpy(), cmap='tab20')
    axes[2, 1].set_title('Pred Material')
    axes[2, 1].axis('off')

    axes[2, 2].imshow(predictions['pred_context'][0, 0].numpy(), cmap='viridis')
    axes[2, 2].set_title('Pred Context (ch0)')
    axes[2, 2].axis('off')

    axes[2, 3].imshow(predictions['fused_output'][0, 0].numpy(), cmap='hot')
    axes[2, 3].set_title('Fused Output')
    axes[2, 3].axis('off')

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ… å¯è§†åŒ–ä¿å­˜åˆ°: {save_path}")


def main():
    print("\n" + "=" * 70)
    print("ğŸ” è®­ç»ƒè¯Šæ–­è„šæœ¬")
    print("=" * 70)

    # 1. æ£€æŸ¥æ•°æ®
    batch = check_data_loading()

    # 2. æ£€æŸ¥ä¼ªæ ‡ç­¾
    pseudo_labels = check_pseudo_labels(batch)

    # 3. æ£€æŸ¥æ¨¡å‹
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    predictions = check_model_forward(batch, device)

    # 4. æ£€æŸ¥æŸå¤±
    losses = check_loss_computation(batch, pseudo_labels, predictions)

    # 5. å¯è§†åŒ–
    visualize_outputs(batch, pseudo_labels, predictions)

    print("\n" + "=" * 70)
    print("âœ… è¯Šæ–­å®Œæˆï¼")
    print("=" * 70)
    print(f"\nå¦‚æœlossä¸é™ï¼Œæ£€æŸ¥ï¼š")
    print(f"1. æ•°æ®èŒƒå›´æ˜¯å¦æ­£ç¡® (RGBå½’ä¸€åŒ–, Infrared [0,1])")
    print(f"2. ä¼ªæ ‡ç­¾æ˜¯å¦åˆç†")
    print(f"3. æ¨¡å‹è¾“å‡ºèŒƒå›´æ˜¯å¦åŒ¹é…ä¼ªæ ‡ç­¾")
    print(f"4. æŸå¤±æ•°å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´ (total < 10)")
    print(f"5. æŸ¥çœ‹ debug_vis.png æ£€æŸ¥å¯è§†åŒ–")


if __name__ == '__main__':
    main()
